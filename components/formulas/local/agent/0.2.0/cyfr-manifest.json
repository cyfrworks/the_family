{
  "id": "formula:local.agent",
  "type": "formula",
  "version": "0.2.0",
  "description": "Multi-provider conversational agent with dynamic component discovery",
  "setup": {
    "policy": {
      "allowed_tools": [
        "component.search"
      ],
      "timeout": "5m",
      "max_memory_bytes": 67108864,
      "max_request_size": 1048576,
      "max_response_size": 5242880
    }
  },
  "schema": {
    "input": {
      "type": "object",
      "required": [
        "provider",
        "model"
      ],
      "properties": {
        "provider": {
          "type": "string",
          "description": "Catalyst name to search for (e.g., \"claude\", \"openai\", \"gemini\")"
        },
        "model": {
          "type": "string",
          "description": "Model identifier (e.g., \"claude-sonnet-4-5-20250514\", \"gpt-4o\")"
        },
        "prompt": {
          "type": "string",
          "description": "Simple single-turn prompt (creates a one-message conversation)"
        },
        "system": {
          "type": "string",
          "description": "System prompt"
        },
        "messages": {
          "type": "array",
          "description": "Full conversation history; takes precedence over prompt"
        },
        "stream": {
          "type": "boolean",
          "description": "Use streaming operation when available (default: true)"
        },
        "params": {
          "type": "object",
          "description": "Additional provider-specific params merged into the request"
        }
      }
    },
    "output": {
      "type": "object",
      "properties": {
        "provider": {
          "type": "string"
        },
        "model": {
          "type": "string"
        },
        "content": {
          "type": "string"
        },
        "stream": {
          "type": "boolean"
        },
        "component_ref": {
          "type": "string"
        }
      }
    }
  },
  "dependencies": {
    "dynamic": {
      "discovery": "component.search",
      "description": "Discovers AI provider catalysts at runtime via MCP search based on the 'provider' input parameter",
      "typical_types": [
        "catalyst"
      ]
    }
  },
  "examples": [
    {
      "name": "Chat with Claude",
      "input": {
        "provider": "claude",
        "model": "claude-sonnet-4-5-20250514",
        "prompt": "Hello",
        "system": "Be concise"
      },
      "output": {
        "provider": "claude",
        "content": "Hello! How can I help?",
        "stream": true
      }
    },
    {
      "name": "Chat with OpenAI",
      "input": {
        "provider": "openai",
        "model": "gpt-4o",
        "prompt": "What is 2+2?",
        "system": "Answer briefly"
      },
      "output": {
        "provider": "openai",
        "content": "4",
        "stream": true
      }
    },
    {
      "name": "Chat with Gemini",
      "input": {
        "provider": "gemini",
        "model": "gemini-2.0-flash",
        "prompt": "Say hello",
        "stream": false
      },
      "output": {
        "provider": "gemini",
        "content": "Hello!",
        "stream": false
      }
    }
  ]
}